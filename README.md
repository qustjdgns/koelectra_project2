# SOOP 유저 게시글 분석


# 1. 서론 (Introduction)

## 문제 정의 및 프로젝트 개요

본 프로젝트는 대규모 SOOP 유저 게시글을 분석하여 서비스 운영의 효율성을 극대화하는 것을 목표로 한다. 고객센터나 운영팀이 수많은 건의 및 버그 제보를 수동으로 처리할 때 발생하는 시간 지연과 중요 이슈 누락 문제를 해결하고자 한다.

- **주요 목표**: 유저 게시글 텍스트를 분석하여 이슈의 긴급도(Urgency)를 3단계(높음, 보통, 낮음)로 자동 분류하는 KoELECTRA 딥러닝 모델을 구축한다.
- **프로젝트 의미**: 단순 분류를 넘어, 토픽 모델링을 통해 유저들이 논의하는 잠재적 이슈 구조와 시계열적 심리 변화를 분석하여 데이터 기반의 서비스 운영 방향을 제시한다.

---

## 분석 대상 데이터

- **데이터 소스**: SOOP 소통센터 (유저 게시판)  
- **수집 목표량**: 전처리 후 최소 2만 건 이상 확보를 위해 2만 5천 건 ~ 3만 건의 게시글 데이터를 수집한다.

---

# 2. 데이터 수집 및 크롤링

## 2.1. 데이터 수집 방법 및 코드

대규모 게시글 목록을 페이지네이션 방식으로 크롤링하기 위해 Python의 Selenium 라이브러리를 사용한다.

- **크롤링 도구**: Selenium + Chrome Driver
- **수집 대상 항목**: `post_id`, `title`, `author`, `date`, `views`, `recommends`, `detail_url`, `content` (상세 페이지에서 추출)

### 크롤링 코드 (핵심 로직)

크롤링 코드의 핵심은 목록에서 링크를 획득하고 상세 페이지의 본문을 추출하는 2단계 크롤링이다.

```python
# CONTENT_SELECTOR가 정확해야 한다. (현재 추정값: div.view_contents)
CONTENT_SELECTOR = "div.view_contents" 

def crawl_detail_content(driver, item):
    # 상세 페이지로 이동하여 본문 텍스트를 추출한다.
    try:
        driver.get(item['detail_url'])
        time.sleep(SLEEP_TIME_DETAIL) 

        # 1. 본문 텍스트 추출 (가장 중요한 CSS 선택자)
        content_element = driver.find_element(By.CSS_SELECTOR, CONTENT_SELECTOR) 
        item['content'] = content_element.text.strip()

    except NoSuchElementException:
        item['content'] = "본문 영역 찾기 실패" 
    # ... (데이터 저장) ...
```

 **[첨부 파일 경로]**  
- 크롤링 코드: `soop_crawler_final.py` (GitHub 저장소에 업로드한다.)  
- 수집 데이터: 저작권 문제로 업로드하지 않는다고 명시한다.

---

## 2.2. 데이터 수집 결과

| 구분             | 목표 수량     | 실제 수집된 데이터 수 |
|------------------|---------------|------------------------|
| 총 게시글 (Raw Data) | 25,000건 이상 | [사용자가 수집된 최종 건수 입력] |

- **수집 기간**: [크롤링 시작일] ~ [크롤링 종료일]  
- [실제 크롤링 기간 입력]

---

# 3. 데이터 라벨링 과정 상세

## 3.1. 학습 데이터 추출 기준

수집된 전체 데이터 중 최소 2,000건 이상을 추출하여 수동 라벨링을 수행한다.

- **무작위 샘플링 (1,000건)**: 일반적인 유저 건의 분포를 반영한다.
- **전략적 샘플링 (1,000건 이상)**: 조회 수 및 추천 수가 높은 게시글이나 긴급 키워드를 포함한 게시글을 우선 추출하여 긴급도가 높은 클래스(2)를 확보한다.

---

## 3.2. 라벨 정의 (긴급도 분류)

라벨링의 일관성을 위해 다음과 같이 긴급도 기준을 설정하고, `soop_data_labeling_sample.csv` 파일에 수동으로 라벨 값을 입력한다.

| 라벨 값 | 라벨 명       | 정의 (Urgency Criteria) |
|---------|---------------|--------------------------|
| 2       | 높음 (High)   | 핵심 서비스 장애, 결제 오류, 접속 불능, 법적 문제 제기 등 즉각 대응이 필요하다. |
| 1       | 보통 (Medium) | UI/UX 개선 요청, 기능 추가 건의, 소수 유저의 불편 사항 등 편의성 및 보조 기능 개선 사항이다. |
| 0       | 낮음 (Low)    | 단순 문의, 응원/격려 메시지, 이미 해결된 문제에 대한 질문 등 서비스 운영에 영향이 없는 내용이다. |

---

# 4. 탐색적 데이터 분석 (EDA)

## 4.1. 데이터의 기본적인 전처리

모델 학습에 적합한 데이터셋 구축을 위해 다음과 같은 전처리를 수행한다.

- **결측치 제거**: `content` (본문)가 비어 있거나, 라벨링이 불가능한 행을 제거한다.
- **정규화**: `views` (조회) 및 `recommends` (추천) 필드를 숫자형으로 변환한다.
- **텍스트 정제 및 토큰화**: URL, HTML 태그, 불필요한 특수 문자를 제거하고, `KoNLPy`를 활용하여 불용어(Stop Word)를 정의 및 제거한다.

## 4.2. 데이터의 분포 시각화

- **라벨 분포 시각화**: 긴급도 0, 1, 2의 비율을 막대 그래프로 시각화한다.  
  *(결과: [실제 분포 결과 입력, 예: 0이 가장 많고 2가 가장 적음])*

- **키워드 비교 시각화**: 긴급도 '높음(2)' 게시글에서 '버그', '오류', '결제' 등의 키워드가 두드러지는지 확인한다.

---

# 5. 학습 결과

## 5.1. Epoch별 학습 정확도 / 검증 정확도 그래프

KoELECTRA 모델 학습 결과는 다음과 같다:

> [Epoch별 학습 정확도/검증 정확도 그래프 삽입]

- **결과 해석**:  
  Training Accuracy는 Epoch가 증가함에 따라 [증가/감소]했지만, Validation Accuracy는 [특징 입력, 예: 2 Epoch 이후 정체/하락]하는 경향을 보였다. 이는 [과적합(Overfitting) 발생 여부]를 시사한다.

## 5.2. 최종 모델 성능 (혼동 행렬 및 리포트)

> [최종 혼동 행렬 시각화 삽입]  
> Classification Report:

```
[Classification Report 결과 텍스트 복사/붙여넣기]
```

- **결론**: 긴급도 '높음(2)' 클래스의 **재현율(Recall)** 은 **[수치 입력]%**로 나타났다. 이는 모델이 긴급 이슈를 놓치지 않고 잘 감지하고 있음을 의미한다.

---

# 6. 결론 및 심층 분석

## 6.1. 토픽 모델링, 키워드 네트워크 분석 (군집 알고리즘)

전처리된 전체 코퍼스(25,000건)를 대상으로 LDA (Latent Dirichlet Allocation) 토픽 모델링을 수행한다.

- **결과**: 유저들이 주로 논의하는 **[토픽 개수 입력]개의 잠재적 토픽**을 추출한다.
- **키워드 네트워크**: 특히 긴급도가 높은 토픽에서 **'[키워드 1]', '[키워드 2]'** 가 강한 연결고리를 보이는 키워드 네트워크를 확인한다.

## 6.2. 분류에 따른 시계열적인 특성

모델이 최종 분류한 긴급도 '높음(2)' 게시글의 발생 시점을 분석한다.

- **분석 결과**: [특정 시기 입력, 예: 서버 점검 공지 직후 12시간 동안] 동안 긴급도 '높음' 게시글의 수가 평균 대비 **[수치 입력]%** 증가하는 spike 현상을 보였다.
- **해석**: 이는 서비스 운영팀의 이벤트/공지사항 발표 시점이 유저들의 민감도를 증폭시키며 긴급 이슈 제보를 유발한다는 것을 보여준다.

## 6.3. 주장이나 현상을 뒷받침하는 근거들

프로젝트를 통해 다음과 같은 결론을 도출한다.

- **주장**: 현재 SOOP 플랫폼에서 유저들에게 가장 치명적인 불편을 주는 문제는 **'결제/환불' 및 '접속 불안정/송출 오류'** 문제이며, 이는 운영팀의 최우선 해결 과제로 제시되어야 한다.
- **근거**: 모델이 긴급도 '높음(2)'으로 분류한 게시글에서 해당 키워드들이 **압도적으로 높은 빈도와 연결성**을 보였기 때문이다.

---
