# SOOP 유저 게시글 분석


# 1. 서론 (Introduction)

## 문제 정의 및 프로젝트 개요

본 프로젝트는 대규모 SOOP 유저 게시글을 분석하여 서비스 운영의 효율성을 극대화하는 것을 목표로 한다.  
운영팀 또는 고객센터가 수많은 게시글을 수작업으로 분류하는 과정에서 발생하는 시간 지연과 중요 이슈 누락 문제를 해결하고자 하였다.

### 주요 목표

게시글 텍스트를 분석하여 아래 5개 유형으로 자동 분류하는 KoELECTRA 딥러닝 분류 모델을 구축한다.

| 라벨 | 의미 |
|------|------|
| 0 | 기능건의 |
| 1 | 기술오류 |
| 2 | 정책비판 |
| 3 | 공지 |
| 4 | 기타 |

또한 단순 분류를 넘어 토픽 모델링과 시계열 분석을 통해  
유저가 체감하는 서비스 문제 구조를 데이터로 해석하는 것을 목표로 한다.

---

### 1.2 분석 대상 데이터

- 데이터 소스: SOOP 소통센터 (유저 게시판)
- 수집 목표량: 약 25,000 ~ 30,000건
- 실제 전처리 후 데이터 수: **24,905건**


---

# 2. 데이터 수집 및 크롤링

## 2.1. 데이터 수집 방법 및 코드

대규모 게시글 목록을 페이지네이션 방식으로 크롤링하기 위해 Python의 Selenium 라이브러리를 사용한다.

- **크롤링 도구** : Selenium + Chrome Driver
- **수집 대상 항목** : `post_id`, `title`, `author`, `date`, `views`, `recommends`, `detail_url`, `content` (상세 페이지에서 추출)

### 크롤링 코드 

크롤링 코드의 핵심은 목록에서 링크를 획득하고 상세 페이지의 본문을 추출하는 2단계 크롤링이다.

```python
# CONTENT_SELECTOR가 정확해야 한다. (현재 추정값: div.view_contents)
CONTENT_SELECTOR = "div.view_contents" 

def crawl_detail_content(driver, item):
    # 상세 페이지로 이동하여 본문 텍스트를 추출한다.
    try:
        driver.get(item['detail_url'])
        time.sleep(SLEEP_TIME_DETAIL) 

        # 1. 본문 텍스트 추출 (가장 중요한 CSS 선택자)
        content_element = driver.find_element(By.CSS_SELECTOR, CONTENT_SELECTOR) 
        item['content'] = content_element.text.strip()

    except NoSuchElementException:
        item['content'] = "본문 영역 찾기 실패" 
    # ... (데이터 저장) ...
```


- 크롤링 코드: `soop.py` 
- 수집 데이터: 저작권 문제로 업로드하지 않는다.
- 수집 기간: **2018-09-16 ~ 2025-11-26**
- 실제 전처리 후 데이터 수: **24,905건**
  
---

### 2.2 수집 결과 요약

| 항목 | 목표 | 실제 |
|------|------|------|
| 게시글 수 | 25,000건 이상 | **24,905건** |

---

## 3. 데이터 라벨링 과정

### 3.1 샘플링 전략
전체 데이터 중 2,000건 이상을 수동 라벨링 대상으로 선정하였다. 무작위 샘플링과 전략적 샘플링을 병행하여 클래스 불균형을 완화하고, 중요 이슈 데이터를 충분히 확보하였다.

전략 기준: 조회 수 상위 10%, 추천 수가 많은 게시글과 더불어, 운영 리스크가 높은 **'기술오류'** 와 '정책비판' 클래스의 게시글을 우선 추출하기 위해 아래의 핵심 키워드 목록을 활용하였다.

### 3.2 라벨 정의 및 초기 분류
수동 라벨링 작업의 효율성을 높이기 위해, 게시글 content 텍스트에 기반한 키워드 매칭 방식으로 초기 분류 작업을 수행하였다. 특히 운영자 공지(3)나 기술 오류(1) 등 중요 클래스를 우선적으로 필터링하는 데 활용되었다.

활용된 이슈 유형 분류 키워드 목록 (URGENCY_KEYWORDS)

라벨 3 (공지): '안녕하세요', '소통센터장', '공지' 등 운영자 관련 키워드를 최우선으로 검출.

라벨 1 (기술오류): '오류', '버그', '결제', '환불', '팅기는' 등 즉각적인 기술 결함 관련 키워드.

라벨 2 (정책비판): '블랙', '차단', '제재', '정책', '숨기기' 등 운영 정책 및 비판 관련 키워드.

라벨 0 (기능건의): '개선', '요청', 'UI', '혜택', '포인트' 등 기능 추가 및 개선 관련 키워드.

라벨 4 (기타): 상위 키워드에 포함되지 않는 일반 게시글.

---

###  라벨 정의 요약

| 라벨 | 클래스 | 의미 |
|------|--------|------|
| 0 | 기능건의 | 기능 추가, UX 개선 |
| 1 | 기술오류 | 버그, 결제 오류 |
| 2 | 정책비판 | 운영 및 제재 관련 비판 |
| 3 | 공지 | 운영 공지 |
| 4 | 기타 | 일반 게시글, 잡담 |

---

## 4. 탐색적 데이터 분석 (EDA)

### 4.1 데이터 전처리

모델 학습을 위해 다음과 같은 전처리를 수행하였다.

- 결측치 제거
- post_id 기준 중복 제거
- 숫자형 컬럼 변환 (views, recommends)
- 특수문자 및 HTML 태그 제거
- KoNLPy 기반 불용어 제거
- 명사 토큰화

---

### 4.2 라벨 분포

<img width="800" height="600" alt="Figure_3" src="https://github.com/user-attachments/assets/a9ac58bb-943e-45fa-9474-8ba03552c386" />


---

## 5. 딥러닝 모델 학습 결과

### 5.1 학습 설정

- 모델: `monologg/koelectra-base-v3-discriminator`
- 클래스 수: 5
- Batch Size: 32
- Epoch: 4
- Optimizer: AdamW

---

### 5.2 Epoch별 학습 결과

<img width="1000" height="600" alt="Figure_2" src="https://github.com/user-attachments/assets/c32b189e-3db5-4d99-b768-6c2b23ee5648" />


#### 학습 해석

- Epoch가 증가함에 따라 **Loss는 안정적으로 감소**하였다.
- Validation Accuracy는 약 **94% 수준으로 수렴**하며 높은 성능을 보였다.

---

### 5.3 혼동 행렬 (Confusion Matrix)

<img width="1000" height="800" alt="Figure_1" src="https://github.com/user-attachments/assets/8c309d66-556a-45e8-addd-c99612a56f85" />

- **결론**: 기술오류(1) 및 정책비판(2) 클래스의 재현율(Recall)이 각각 91.7%, 87.6%로 측정되었다.
이는 모델이 서비스 운영 리스크와 직결되는 이슈를 효과적으로 감지하고 있음을 의미한다.
 
### 5.4 Classification Report

| 클래스 | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| 기능건의(0) | 0.9258 | 0.9423 | 0.9340 | 1,231 |
| 기술오류(1) | 0.9674 | 0.9170 | 0.9415 | 711 |
| 정책비판(2) | 0.8396 | 0.8761 | 0.8574 | 460 |
| 공지(3) | 0.6914 | 0.6512 | 0.6707 | 86 |
| 기타(4) | 0.9683 | 0.9683 | 0.9683 | 2,493 |
| **전체 정확도** | - | **0.9406** | - | 4,981 |
| **Macro Avg** | 0.8785 | 0.8710 | 0.8744 | 4,981 |
| **Weighted Avg** | 0.9410 | 0.9406 | 0.9406 | 4,981 |

## 5.5 성능 분석 요약

### 모델 성능 핵심 결과

- 전체 정확도: **94.06%**
- 가장 잘 분류된 클래스:
  - 기타(4)
  - 기술오류(1)
- 가장 어려운 클래스:
  - 공지(3) → 데이터 수 부족의 영향으로 오분류율 상대적으로 높음

---

### 핵심 Recall 성능

| 클래스 | Recall |
|--------|--------|
| 기술오류(1) | **91.7%** |
| 정책비판(2) | **87.6%** |

➡ **운영 리스크 자동 감지에 충분한 모델 성능 확보**

---

## 6. 토픽 모델링 및 시계열 분석

### 6.1 토픽 모델링 (LDA)

전체 데이터 **24,905건**을 대상으로 LDA 토픽 모델링을 수행하였다.

#### 분석 설정

- 명사 기반 벡터화
- 불용어 제거
- 토픽 수: **5개**

#### 예시 토픽

```text
Topic 1: 결제, 환불, 오류, 접속
Topic 2: 정지, 신고, 제재
Topic 3: 기능, 개선, UI
Topic 4: 점검, 공지, 업데이트
Topic 5: BJ, 방송, 채팅
### 6.2 시계열 분석
```

기술오류(1) 및 정책비판(2) 클래스를 중심으로 **시간대별 발생 패턴**을 분석하였다.

#### 분석 내용

- 게시글 발생 시간 기준 정렬
- 클래스별 발생 빈도 시각화
- 주요 이벤트(서버 점검, 정책 변경) 시점 전후 비교

#### 관찰 결과

- 서버 점검 직후  
  → 기술오류(1), 정책비판(2) 게시글 **급증**
- 특정 시점에서 **Spike 패턴** 반복 관찰

> 이는 서비스 운영 이벤트가 유저 불만 발생 양상에 직접적인 영향을 미친다는 것을 의미한다.

---

## 7. 결론

### 핵심 인사이트

- 기술 이슈는 비중은 작지만 **영향력은 절대적**
- 유저는 특히 **결제 시스템과 네트워크 안정성**에 민감
- 공지 이후 불만 게시글 집중 현상 반복적으로 관측

---

### 최종 결론

SOOP 서비스 운영에서 최우선 개선 과제는 다음과 같다.

 **결제 시스템 안정화**  
 **방송 인프라 품질 개선**
